{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GBloNPbPQuq0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sort import Sort\n",
        "\n",
        "# Load the pre-trained TensorFlow model\n",
        "model = tf.saved_model.load(\"/content/ssd_mobilenet_v2_coco/saved_model\")\n",
        "\n",
        "# Create SORT tracker\n",
        "tracker = Sort()\n",
        "\n",
        "# Upload the video file and the sort.py file to Colab\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the video file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract the uploaded files\n",
        "!unzip sort.zip\n",
        "\n",
        "# Replace 'your_video_filename.mp4' with the actual file name\n",
        "video_path = \"/content/your_video_filename.mp4\"\n",
        "\n",
        "# Open a video capture\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Prepare the image for object detection\n",
        "    input_tensor = tf.convert_to_tensor([frame])\n",
        "    detections = model(input_tensor)\n",
        "\n",
        "    # Process the detections\n",
        "    boxes = []\n",
        "    for detection in detections['detection_boxes'][0].numpy():\n",
        "        ymin, xmin, ymax, xmax = detection\n",
        "        xmin, xmax, ymin, ymax = int(xmin * frame.shape[1]), int(xmax * frame.shape[1]), \\\n",
        "                                 int(ymin * frame.shape[0]), int(ymax * frame.shape[0])\n",
        "        boxes.append([xmin, ymin, xmax - xmin, ymax - ymin])\n",
        "\n",
        "    # Apply SORT tracker for object tracking\n",
        "    trackers = tracker.update(np.array(boxes))\n",
        "    for i, new_box in enumerate(trackers):\n",
        "        x, y, w, h, track_id = map(int, new_box)\n",
        "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Person {int(track_id)}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Intelligent Camera Decision-Making', frame)\n",
        "\n",
        "    # Break the loop if 'q' key is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the capture and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}